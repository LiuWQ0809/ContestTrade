"""
Simplified Trade Company - åˆå¹¶æ‰€æœ‰ä»£ç ï¼ŒåŒ…è£…æˆLangGraphå·¥ä½œæµ
"""
import re
import json
import asyncio
from loguru import logger
from datetime import datetime
from typing import List, Dict, TypedDict
from langgraph.graph import END, StateGraph
from langchain_core.runnables import RunnableConfig
from langchain_core.callbacks import dispatch_custom_event
from config.config import cfg, PROJECT_ROOT, WORKSPACE_ROOT
from agents.data_analysis_agent import DataAnalysisAgent, DataAnalysisAgentConfig, DataAnalysisAgentInput
from agents.research_agent import ResearchAgent, ResearchAgentConfig, ResearchAgentInput
from utils.market_manager import GLOBAL_MARKET_MANAGER

# ç»Ÿä¸€çš„çŠ¶æ€å®šä¹‰
class CompanyState(TypedDict):
    trigger_time: str
    data_factors: List[Dict]
    research_signals: List[Dict]
    all_events: List[Dict]
    step_results: Dict
    portfolio_info: Dict  # æ–°å¢ï¼šè´¦æˆ·èµ„é‡‘å’ŒæŒä»“ä¿¡æ¯

class SimpleTradeCompany:
    def __init__(self):
        # è®¾ç½®å·¥ä½œç›®å½•
        self.workspace_dir = str(WORKSPACE_ROOT / "agents_workspace")
        
        # åˆå§‹åŒ–Data Agents
        self.data_agents = {}
        for agent_config_idx, agent_config in enumerate(cfg.data_agents_config):
            custom_config = DataAnalysisAgentConfig(
                source_list=agent_config["data_source_list"],
                agent_name=agent_config["agent_name"],
                final_target_tokens=agent_config.get("final_target_tokens", 4000),
                bias_goal=agent_config.get("bias_goal", ""),
            )
            self.data_agents[agent_config_idx] = DataAnalysisAgent(custom_config)
        
        # åˆå§‹åŒ–Research Agents
        self.research_agents = {}

        # ä»belief_list.jsonè¯»å–beliefé…ç½®
        belief_list_path = PROJECT_ROOT / cfg.research_agent_config["belief_list_path"]
        with open(belief_list_path, 'r', encoding='utf-8') as f:
            belief_list = json.load(f)

        for agent_config_idx, belief in enumerate(belief_list):
            custom_config = ResearchAgentConfig(
                agent_name=f"agent_{agent_config_idx}",
                belief=belief,
            )
            self.research_agents[agent_config_idx] = ResearchAgent(custom_config)

    # LangGraphèŠ‚ç‚¹å‡½æ•°
    async def run_data_agents_step(self, state: CompanyState, config: RunnableConfig) -> CompanyState:
        """è¿è¡ŒData Agentsæ­¥éª¤"""
        trigger_time = state["trigger_time"]
        
        logger.info("ğŸš€ å¼€å§‹å¹¶å‘è¿è¡ŒData Agents...")
        
        # åˆ›å»ºå¹¶å‘ä»»åŠ¡
        agent_tasks = []
        for agent_id, agent in self.data_agents.items():
            task = self._run_single_data_agent(agent_id, agent, trigger_time, config)
            agent_tasks.append(task)
        
        # å¹¶å‘æ‰§è¡Œ
        results = await asyncio.gather(*agent_tasks)
        
        # æ”¶é›†ç»“æœ
        all_factors = []
        all_events = []
        for result in results:
            if result:
                all_factors.append(result["factor"])
                all_events.extend(result["events"])
        
        logger.info(f"âœ… Data Agentså®Œæˆï¼Œæœ‰æ•ˆç»“æœ: {len(all_factors)}")
        
        # æ›´æ–°çŠ¶æ€
        all_events_state = state["all_events"].copy()
        all_events_state.extend(all_events)
        
        step_results = state["step_results"].copy()
        step_results["data_team"] = {"factors_count": len(all_factors), "events_count": len(all_events)}
        
        return {
            "data_factors": all_factors,
            "all_events": all_events_state,
            "step_results": step_results
        }

    async def run_research_agents_step(self, state: CompanyState, config: RunnableConfig) -> CompanyState:
        """è¿è¡ŒResearch Agentsæ­¥éª¤ - å¹¶è¡ŒåŒ–ä¼˜åŒ–ç‰ˆ"""
        trigger_time = state["trigger_time"]
        data_factors = state["data_factors"]
        portfolio_info = state.get("portfolio_info", {})
        
        if not data_factors:
            logger.warning("No data factors found, skipping research step.")
            return state

        # ä¼˜åŒ–ï¼šå¹¶è¡ŒåŒ–å¤„ç†é€»è¾‘
        # æˆ‘ä»¬å°† data_factors è¿›è¡Œåˆ†å—ï¼Œæ¯ä¸ª Agent è´Ÿè´£å¤„ç†ä¸€å°å—èµ„è®¯ï¼Œ
        # ä»è€Œå®ç°â€œå¹¶è¡Œåˆ†æå¤šä¸ªå€™é€‰ç¥¨â€ï¼Œæ˜¾è‘—é™ä½ Qwen æ€è€ƒæ¨¡å¼çš„ä¸²è¡Œç­‰å¾…æ—¶é—´ã€‚
        num_factors = len(data_factors)
        num_chunks = 2 if num_factors > 1 else 1 # æŒ‰ç…§ 2 ä¸ªåˆ†å—è¿›è¡Œåˆæ­¥æ‹†åˆ†ï¼Œå¯æ ¹æ®èµ„æºè°ƒæ•´
        
        # è¿™ç§åˆ†å—æ–¹å¼å¯ä»¥ç¡®ä¿ä¸åŒçš„èµ„è®¯å—è¢«ä¸åŒçš„ Agent å®ä¾‹å¹¶å‘å¤„ç†
        factor_chunks = []
        chunk_size = (num_factors + num_chunks - 1) // num_chunks
        for i in range(0, num_factors, chunk_size):
            factor_chunks.append(data_factors[i:i + chunk_size])

        logger.info(f"ğŸš€ æ­£åœ¨å¹¶å‘è¿è¡Œ Research Agents (åˆ†å—å¹¶è¡ŒåŒ–: {len(self.research_agents)} ç­–ç•¥ x {len(factor_chunks)} æ•°æ®å—)...")
        
        # åˆ›å»ºå¹¶å‘ä»»åŠ¡
        agent_tasks = []
        for agent_id, agent in self.research_agents.items():
            for chunk_id, chunk_data in enumerate(factor_chunks):
                # å”¯ä¸€çš„å­ä»»åŠ¡ ID
                sub_task_id = f"{agent_id}_{chunk_id}"
                task = self._run_single_research_agent(sub_task_id, agent, trigger_time, chunk_data, config, portfolio_info)
                agent_tasks.append(task)
        
        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰å­ä»»åŠ¡
        results = await asyncio.gather(*agent_tasks)
        
        # æ”¶é›†ç»“æœ
        all_signals = []
        all_events = []
        for result in results:
            if result and result["signals"]:
                all_signals.extend(result["signals"])
                all_events.extend(result["events"])
        
        # å¯¹ä¿¡å·è¿›è¡Œå»é‡ï¼ˆå¯èƒ½å¤šå—æ•°æ®æåˆ°äº†åŒä¸€ä¸ªå¥½æœºä¼šï¼‰
        unique_signals = []
        seen_symbols = set()
        for sig in sorted(all_signals, key=lambda x: x.get('probability', 0), reverse=True):
            sym = sig.get('symbol_code')
            if sym not in seen_symbols:
                unique_signals.append(sig)
                seen_symbols.add(sym)
        
        logger.info(f"âœ… Research Agentså¹¶è¡Œå®Œæˆï¼ŒåŸå§‹ä¿¡å·: {len(all_signals)}, å»é‡åä¿¡å·: {len(unique_signals)}")
        
        # æ›´æ–°çŠ¶æ€
        all_events_state = state["all_events"].copy()
        all_events_state.extend(all_events)
        
        step_results = state["step_results"].copy()
        step_results["research_team"] = {"signals_count": len(unique_signals), "events_count": len(all_events)}
        
        return {
            "research_signals": unique_signals,
            "all_events": all_events_state,
            "step_results": step_results
        }

    async def finalize_step(self, state: CompanyState, config: RunnableConfig) -> CompanyState:
        """æœ€ç»ˆç»“æœæ­¥éª¤"""
        trigger_time = state["trigger_time"]
        data_factors = state["data_factors"]
        research_signals = state["research_signals"]
        all_events = state["all_events"]
        step_results = state["step_results"]
        
        logger.info("ğŸš€ å¼€å§‹æœ€ç»ˆç»“æœæ­¥éª¤...")
        # ä¼˜å…ˆä½¿ç”¨researchäº§ç”Ÿçš„ä¿¡å·ä½œä¸ºæœ€ç»ˆæœ€ä½³ä¿¡å·
        best_signals = research_signals if research_signals else []

        # ç”Ÿæˆæœ€ç»ˆç»“æœï¼ˆä¿ç•™ä½†ä¸é¢å¤–è¾“å‡ºï¼‰
        final_result = {
            "trigger_time": trigger_time,
            "data_factors_count": len(data_factors),
            "research_signals_count": len(research_signals),
            "total_events_count": len(all_events),
            "best_signals": best_signals,
            "step_results": step_results
        }

        logger.info("âœ… æœ€ç»ˆç»“æœæ­¥éª¤å®Œæˆ")

        step_results = state["step_results"]
        step_results["contest"] = {
            "best_signals": best_signals
        }
        return {
            "step_results": step_results
        }

    # è¾…åŠ©å‡½æ•°
    async def _run_single_data_agent(self, agent_id: int, agent, trigger_time: str, config: RunnableConfig):
        """è¿è¡Œå•ä¸ªdata agent"""
        logger.info(f"ğŸ” å¼€å§‹è¿è¡ŒData Agent {agent_id} ({agent.config.agent_name})...")
        
        agent_input = DataAnalysisAgentInput(trigger_time=trigger_time)
        agent_events = []
        agent_output = None
        
        # è¿è¡Œagentå¹¶æ”¶é›†äº‹ä»¶
        async for event in agent.run_with_monitoring_events(agent_input, config):
            # è½¬å‘äº‹ä»¶
            if event["event"] == "on_custom":
                dispatch_custom_event(
                    name=f"data_agent_{agent_id}_{event['name']}", 
                    data={**event.get('data', {}), "agent_id": agent_id, "agent_name": agent.config.agent_name},
                    config=config
                )
            else:
                dispatch_custom_event(
                    name=f"data_agent_{agent_id}_{event['event']}", 
                    data={"agent_id": agent_id, "agent_name": agent.config.agent_name, "sub_node": event.get('name', 'unknown')},
                    config=config
                )
            
            agent_events.append({**event, "agent_id": agent_id, "agent_name": agent.config.agent_name})
            
            # è·å–æœ€ç»ˆç»“æœ
            if event["event"] == "on_chain_end" and event.get("name") == "submit_result":
                agent_output = event.get("data", {}).get("output", {})
        
        # å¤„ç†ç»“æœ
        factor = None
        if agent_output:
            factor = agent_output['result']
        return {"factor": factor, "events": agent_events} if factor else None

    async def _run_single_research_agent(self, agent_id: int, agent, trigger_time: str, factors: List, config: RunnableConfig, portfolio_info: Dict = None):
        """è¿è¡Œå•ä¸ªresearch agent"""
        logger.info(f"ğŸ” å¼€å§‹è¿è¡ŒResearch Agent {agent_id} ({agent.config.agent_name})...")
        
        # æ„å»ºèƒŒæ™¯ä¿¡æ¯ï¼ŒåŠ å…¥è´¦æˆ·ä¿¡æ¯
        background_information = agent.build_background_information(trigger_time, agent.config.belief, factors)
        
        if portfolio_info:
            cash = portfolio_info.get("cash", 0)
            holdings = portfolio_info.get("holdings", {})
            total_fees = portfolio_info.get("total_fees", 0)
            holdings_str = ", ".join([f"{h.get('name', k)}({k})" for k, h in holdings.items()]) if holdings else "æ— "
            account_context = f"\n<account_info>\nå½“å‰å¯ç”¨ç°é‡‘: {cash:.2f}\nå½“å‰æŒä»“è‚¡ç¥¨: {holdings_str}\nç´¯è®¡å·²æ”¯ä»˜äº¤æ˜“è´¹: {total_fees:.2f}\n"
            account_context += "äº¤æ˜“è´¹ç‡æç¤º: Aè‚¡äº¤æ˜“å­˜åœ¨æˆæœ¬ (ä½£é‡‘0.03%[æœ€ä½5å…ƒ], å–å‡ºé¢å¤–å°èŠ±ç¨0.05%, è¿‡æˆ·è´¹ç­‰)ã€‚å•ç¬”ä¹°å…¥5000å…ƒçº¦äº§ç”Ÿ6.5å…ƒè´¹ç”¨ï¼Œå–å‡ºçº¦äº§ç”Ÿ9å…ƒè´¹ç”¨ã€‚è¯·é¿å…ä¹°å…¥é¢„æœŸæ¶¨å¹…æ— æ³•è¦†ç›–äº¤æ˜“æˆæœ¬çš„è‚¡ç¥¨ã€‚\n"
            account_context += "ä»»åŠ¡æŒ‡ä»¤: è¯·åŠ¡å¿…å®¡è§†å½“å‰æŒä»“ã€‚å¦‚æœæŒä»“é€»è¾‘ä¾ç„¶æˆç«‹ä¸”è¡¨ç°è¾ƒå¥½ï¼Œå»ºè®® HOLDï¼›å¦‚æœé€»è¾‘å¤±æ•ˆæˆ–æœ‰æ˜æ˜¾æ›´å¥½çš„æ›¿ä»£æœºä¼šï¼Œå»ºè®® SELLã€‚\n"
            if cash < 1000: # å‡è®¾ 1000 ä¸ºèµ·æŠ•é‡‘é¢
                account_context += "æç¤º: å½“å‰å¯ç”¨èµ„é‡‘æä½ã€‚å¦‚æœä½ å‘ç°å¿…é¡»ä¹°å…¥çš„ç»ä½³æœºä¼šï¼Œä½ å¿…é¡»åŒæ—¶è¯†åˆ«å¹¶å»ºè®®å–å‡ºï¼ˆSELLï¼‰å½“å‰æŒä»“ä¸­è¡¨ç°è¾ƒå·®çš„è‚¡ç¥¨ä»¥é‡Šæ”¾èµ„é‡‘ï¼Œå¦åˆ™ä¹°å…¥åŠ¨ä½œæŒ‡ä»¤å°†ä¼šå› èµ„é‡‘ä¸è¶³è€Œå¤±è´¥ã€‚\n"
            account_context += "</account_info>\n"
            background_information = account_context + background_information

        agent_input = ResearchAgentInput(
            trigger_time=trigger_time,
            background_information=background_information
        )
        
        agent_events = []
        agent_output = None

        # è¿è¡Œagentå¹¶æ”¶é›†äº‹ä»¶
        async for event in agent.run_with_monitoring_events(agent_input, config):
            # è½¬å‘äº‹ä»¶
            if event["event"] == "on_custom":
                dispatch_custom_event(
                    name=f"research_agent_{agent_id}_{event['name']}", 
                    data={**event.get('data', {}), "agent_id": agent_id, "agent_name": agent.config.agent_name},
                    config=config
                )
            else:
                dispatch_custom_event(
                    name=f"research_agent_{agent_id}_{event['event']}", 
                    data={"agent_id": agent_id, "agent_name": agent.config.agent_name, "sub_node": event.get('name', 'unknown')},
                    config=config
                )
            
            agent_events.append({**event, "agent_id": agent_id, "agent_name": agent.config.agent_name})
            
            # è·å–æœ€ç»ˆç»“æœ
            if event["event"] == "on_chain_end" and event.get("name") == "submit_result":
                agent_output = event.get("data", {}).get("output", {})
        
        # å¤„ç†ç»“æœ - è§£æå¤šä¸ªä¿¡å·
        signals = []
        if agent_output:
            if "result" in agent_output and agent_output["result"]:
                result_obj = agent_output["result"]
                signals = self._parse_multiple_results(result_obj.final_result_thinking, result_obj.final_result)
            else:
                signals = self._parse_multiple_results(agent_output.get("final_result_thinking", ""), agent_output.get("final_result", ""))
            
            # ä¸ºæ¯ä¸ªä¿¡å·æ·»åŠ agentä¿¡æ¯ï¼Œæœ€å¤šå–5ä¸ªä¿¡å·
            valid_signals = []
            for i, signal in enumerate(signals[:5]):
                if signal:
                    signal["agent_id"] = agent_id
                    signal["agent_name"] = agent.config.agent_name
                    signal["signal_index"] = i + 1
                    valid_signals.append(signal)
            signals = valid_signals
        
        return {"signals": signals, "events": agent_events} if signals else None

    def _parse_multiple_results(self, thinking_result: str, output_result: str):
        """è§£æå¤šä¸ªä¿¡å·ç»“æœ"""
        thinking = thinking_result.split("<Output>")[0].strip('\n').strip()
        output = output_result.split("<Output>")[-1].strip('\n').strip()
        
        signals = []
        try:
            # æŸ¥æ‰¾æ‰€æœ‰signalå—
            signal_blocks = re.findall(r'<signal>(.*?)</signal>', output, flags=re.DOTALL)
            
            for signal_block in signal_blocks:
                try:
                    signal = self._parse_single_signal_block(signal_block, thinking)
                    if signal:
                        signals.append(signal)
                except Exception as e:
                    logger.error(f"Error parsing individual signal: {e}")
                    continue
        
        except Exception as e:
            logger.error(f"Error parsing multiple results: {e}")
        
        return signals

    def _parse_single_signal_block(self, signal_block: str, thinking: str):
        """è§£æå•ä¸ªä¿¡å·å—"""
        def extract_tag(tag, text, default=""):
            match = re.search(f"<{tag}>(.*?)</{tag}>", text, flags=re.DOTALL)
            return match.group(1).strip() if match else default

        try:
            has_opportunity = extract_tag("has_opportunity", signal_block, "no")
            action = extract_tag("action", signal_block, "hold")
            symbol_code = extract_tag("symbol_code", signal_block, "N/A")
            symbol_name = extract_tag("symbol_name", signal_block, "N/A")
            
            # è§£æevidence_list
            evidence_list = []
            evidence_list_match = re.search(r"<evidence_list>(.*?)</evidence_list>", signal_block, flags=re.DOTALL)
            if evidence_list_match:
                evidence_list_str = evidence_list_match.group(1)
                for item in evidence_list_str.split("<evidence>"):
                    if '</evidence>' not in item:
                        continue
                    evidence_description = item.split("</evidence>")[0].strip()
                    evidence_time = extract_tag("time", item, "N/A")
                    evidence_from_source = extract_tag("from_source", item, "N/A")
                        
                    evidence_list.append({
                        "description": evidence_description,
                        "time": evidence_time,
                        "from_source": evidence_from_source,
                    })

            # è§£ælimitations
            limitations = []
            limitations_match = re.search(r"<limitations>(.*?)</limitations>", signal_block, flags=re.DOTALL)
            if limitations_match:
                limitations_str = limitations_match.group(1)
                limitations = re.findall(r"<limitation>(.*?)</limitation>", limitations_str, flags=re.DOTALL)
                limitations = [l.strip() for l in limitations]
            
            # è§£æprobability
            probability = extract_tag("probability", signal_block, "0%")
            
            # è§£æhold_period
            hold_period = extract_tag("hold_period", signal_block, "1D")
            
            # ä¿®æ­£symbolä¿¡æ¯
            if symbol_name != "N/A" or symbol_code != "N/A":
                symbol_name, symbol_code = GLOBAL_MARKET_MANAGER.fix_symbol_code("CN-Stock", symbol_name, symbol_code)
            
            return {
                "thinking": thinking,
                "has_opportunity": has_opportunity,
                "action": action,   
                "symbol_code": symbol_code,
                "symbol_name": symbol_name,
                "evidence_list": evidence_list,
                "limitations": limitations,
                "probability": probability,
                "hold_period": hold_period
            }
        except Exception as e:
            logger.error(f"Error parsing single signal block: {e}")
            return None

    # LangGraphå·¥ä½œæµåˆ›å»º
    def create_company_workflow(self):
        """åˆ›å»ºå…¬å¸å·¥ä½œæµ"""
        workflow = StateGraph(CompanyState)

        # æ·»åŠ èŠ‚ç‚¹
        workflow.add_node("run_data_agents", self.run_data_agents_step)
        workflow.add_node("run_research_agents", self.run_research_agents_step)
        workflow.add_node("finalize", self.finalize_step)

        # è®¾ç½®å…¥å£ç‚¹
        workflow.set_entry_point("run_data_agents")

        # å®šä¹‰è¾¹ï¼ˆdata -> research -> finalizeï¼‰
        workflow.add_edge("run_data_agents", "run_research_agents")
        workflow.add_edge("run_research_agents", "finalize")
        workflow.add_edge("finalize", END)

        return workflow.compile()

    async def run_company(self, trigger_time: str, config: RunnableConfig = None, portfolio_info: Dict = None):
        """è¿è¡Œæ•´ä¸ªå…¬å¸æµç¨‹"""
        logger.info("ğŸš€ å¼€å§‹è¿è¡ŒSimplified TradeCompany...")
        
        if config is None:
            config = RunnableConfig(recursion_limit=50)
        
        # åˆ›å»ºåˆå§‹çŠ¶æ€
        initial_state = CompanyState(
            trigger_time=trigger_time,
            data_factors=[],
            research_signals=[],
            all_events=[],
            step_results={},
            portfolio_info=portfolio_info or {}
        )
        
        # è¿è¡Œå·¥ä½œæµ
        workflow = self.create_company_workflow()
        final_state = await workflow.ainvoke(initial_state, config=config)
        
        logger.info("âœ… Simplified TradeCompanyå®Œæˆ")
        logger.info(f"ğŸ“Š æœ€ç»ˆç»“æœ:")
        
        # ä»step_resultsä¸­è·å–æ›´å‡†ç¡®çš„ç»Ÿè®¡ä¿¡æ¯
        step_results = final_state.get('step_results', {})
        data_team_results = step_results.get("data_team", {})
        research_team_results = step_results.get("research_team", {})
        
        data_factors_count = data_team_results.get("factors_count", len(final_state.get('data_factors', [])))
        research_signals_count = research_team_results.get("signals_count", len(final_state.get('research_signals', [])))
        total_events_count = len(final_state.get('all_events', []))
        
        logger.info(f"   æ•°æ®å› å­: {data_factors_count}")
        logger.info(f"   ç ”ç©¶ä¿¡å·: {research_signals_count}")
        logger.info(f"   æ€»äº‹ä»¶: {total_events_count}")
        
        return final_state

    async def run_company_with_events(self, trigger_time: str, config: RunnableConfig = None):
        """ä½¿ç”¨äº‹ä»¶æµè¿è¡Œå…¬å¸"""
        if config is None:
            config = RunnableConfig(recursion_limit=50)
        
        # åˆ›å»ºåˆå§‹çŠ¶æ€
        initial_state = CompanyState(
            trigger_time=trigger_time,
            data_factors=[],
            research_signals=[],
            all_events=[],
            step_results={}
        )
        
        # è¿è¡Œå·¥ä½œæµå¹¶è¿”å›äº‹ä»¶æµ
        workflow = self.create_company_workflow()
        async for event in workflow.astream_events(initial_state, version="v2", config=config):
            yield event

if __name__ == "__main__":
    async def main():
        company = SimpleTradeCompany()
        
        # ä½¿ç”¨äº‹ä»¶æµè¿è¡Œ
        logger.info("ğŸš€ å¼€å§‹æµ‹è¯•Simplified TradeCompanyäº‹ä»¶æµ...")
        logger.info("=" * 60)

        trigger_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        company_events = []
        final_state = None
        
        async for event in company.run_company_with_events(trigger_time):
            company_events.append(event)
            
            # ç›‘å¬å¹¶æ‰“å°äº‹ä»¶
            event_type = event.get("event", "unknown")
            event_name = event.get("name", "unknown")
            
            if event_type == "on_chain_start":
                if event_name != "__start__":
                    logger.info(f"ğŸ”„ Companyå¼€å§‹: {event_name}")
            elif event_type == "on_chain_end":
                if event_name != "__start__":
                    logger.info(f"âœ… Companyå®Œæˆ: {event_name}")
                    if event_name == "finalize":
                        final_state = event.get("data", {}).get("output", {})
            elif event_type == "on_custom":
                custom_name = event.get("name", "")
                custom_data = event.get("data", {})
                
                if custom_name.startswith("data_agent_"):
                    agent_id = custom_data.get("agent_id", "unknown")
                    logger.info(f"ğŸ“Š Data Agent {agent_id}: {custom_name}")
                elif custom_name.startswith("research_agent_"):
                    agent_id = custom_data.get("agent_id", "unknown")
                    logger.info(f"ğŸ” Research Agent {agent_id}: {custom_name}")
                else:
                    logger.info(f"ğŸ¯ è‡ªå®šä¹‰äº‹ä»¶: {custom_name}")
        
        logger.info("=" * 60)
        logger.info(f"âœ… å…¬å¸å·¥ä½œæµå®Œæˆ:")
        if final_state:
            step_results = final_state.get('step_results', {})
            data_team_results = step_results.get("data_team", {})
            research_team_results = step_results.get("research_team", {})
            
            data_factors_count = data_team_results.get("factors_count", len(final_state.get('data_factors', [])))
            research_signals_count = research_team_results.get("signals_count", len(final_state.get('research_signals', [])))
            
            logger.info(f"   æ•°æ®å› å­: {data_factors_count}")
            logger.info(f"   ç ”ç©¶ä¿¡å·: {research_signals_count}")
        else:
            logger.info(f"   æ— æœ€ç»ˆçŠ¶æ€æ•°æ®")
        logger.info(f"   å…¬å¸äº‹ä»¶æ€»æ•°: {len(company_events)}")
        
    asyncio.run(main())